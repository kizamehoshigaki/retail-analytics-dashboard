# ğŸ“Š Retail Analytics Dashboard

An end-to-end data analytics project featuring ETL pipeline with data validation, star schema database design, and interactive Streamlit dashboard.

![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-blue?style=for-the-badge&logo=postgresql)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red?style=for-the-badge&logo=streamlit)
## ğŸŒ Live Demo

ğŸ‘‰ **[View Live Dashboard](https://retail-analytics-dashboard-xd7epno6dywzpzn4lezqjv.streamlit.app/)**
---

## ğŸ¯ Business Questions Answered

- How do sales and profit trend month-over-month?
- Which regions and categories drive profitability?
- Which products generate high revenue but low margins?
- How do customer segments compare in purchasing behavior?
- What are the top-performing products and customers?

---

## ğŸ“ˆ Key Metrics

| Metric | Value |
|--------|-------|
| Total Sales | $2.29M |
| Total Profit | $286K |
| Profit Margin | 12.47% |
| Total Orders | 9,994 |
| Unique Customers | 793 |
| Unique Products | 1,862 |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Superstore CSV â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL Pipeline (Python)          â”‚
â”‚  â€¢ Pandera schema validation    â”‚
â”‚  â€¢ Data quality checks          â”‚
â”‚  â€¢ Reconciliation verification  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Star Schema         â”‚
â”‚  â€¢ 1 Fact table (9,994 records) â”‚
â”‚  â€¢ 4 Dimension tables           â”‚
â”‚  â€¢ 8 KPI Views                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit Dashboard            â”‚
â”‚  â€¢ Interactive visualizations   â”‚
â”‚  â€¢ Real-time filtering          â”‚
â”‚  â€¢ Executive-style KPIs         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Data Validation & Reconciliation

The ETL pipeline includes comprehensive data quality checks:

| Check Type | Description | Status |
|------------|-------------|--------|
| Schema | Column types, nullability | âœ… Passed |
| Range | Quantity > 0, Discount âˆˆ [0,1], Sales â‰¥ 0 | âœ… Passed |
| Uniqueness | Order ID + Product ID combinations | âœ… Verified |
| Business Rule | Ship Date â‰¥ Order Date | âœ… 0 violations |
| Deduplication | Exact line-item duplicates removed | âœ… 8 handled |

### Reconciliation Results

```
Metric              Source          Database        Match
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Sales         $2,297,200.86   $2,297,201.07   âœ…
Total Profit        $286,397.02     $286,397.79     âœ…
Total Orders        9,994           9,994           âœ…
Total Quantity      37,873          37,873          âœ…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Overall Reconciliation: PASSED âœ…
```

---

## âš¡ Performance

| Metric | Value |
|--------|-------|
| ETL Runtime | ~2.2 seconds for 9,994 records |
| Dashboard Queries | Pre-aggregated KPI views for sub-second response |
| Data Freshness | Batch refresh via ETL pipeline |

---

## ğŸ—„ï¸ Database Schema

### Star Schema Design

**Fact Table:**
- `fact_orders` â€” Transaction facts with foreign keys (9,994 records)

**Dimension Tables:**
- `dim_customer` â€” Customer details (793 records)
- `dim_product` â€” Product/category info (1,862 records)
- `dim_location` â€” City/Region/State (632 records)
- `dim_date` â€” Date breakdowns (1,434 records)

### SQL Views for KPIs

| View | Purpose |
|------|---------|
| `vw_overall_kpis` | Summary metrics |
| `vw_daily_sales` | Daily sales trends |
| `vw_monthly_trend` | Monthly performance |
| `vw_sales_by_region` | Regional breakdown |
| `vw_sales_by_category` | Category analysis |
| `vw_sales_by_segment` | Customer segments |
| `vw_top_products` | Best selling products |
| `vw_top_customers` | Top customers |

### Why This Design?

- **Star Schema:** Optimized for analytical queries, reduces joins
- **Pre-aggregated Views:** Dashboard queries run in milliseconds
- **Dimension Tables:** Enable drill-down analysis without redundant data

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Language | Python 3.9+ |
| Database | PostgreSQL |
| Data Validation | Pandera |
| Dashboard | Streamlit |
| Visualization | Plotly |
| ORM | SQLAlchemy |

---

## ğŸ“‚ Project Structure

```
retail-analytics-dashboard/
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ Superstore_data.csv      # Source data
â”œâ”€â”€ Source/
â”‚   â”œâ”€â”€ etl_pipeline.py          # ETL with validation & reconciliation
â”‚   â””â”€â”€ dashboard.py             # Streamlit dashboard
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Clone the repository
```bash
git clone https://github.com/kizamehoshigaki/retail-analytics-dashboard.git
cd retail-analytics-dashboard
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Set up environment
```bash
cp .env.example .env
# Edit .env with your database credentials
```

### 4. Set up PostgreSQL
- Create database named `retaildb`
- Run the star schema SQL (see `schema.sql`)
- Run the views SQL

### 5. Run ETL Pipeline
```bash
python Source/etl_pipeline.py
```

Expected output:
```
âœ… Schema validation: PASSED
âœ… Quality checks: PASSED
âœ… Reconciliation: PASSED
ğŸ‰ ETL COMPLETE!
```

### 6. Launch Dashboard
```bash
streamlit run Source/dashboard.py
```

---

## ğŸ“Š Dashboard Features

- **KPI Cards** â€” Total sales, profit, orders, margin at a glance
- **Monthly Trend** â€” Sales over time with interactive line chart
- **Regional Analysis** â€” Sales distribution by region (pie chart)
- **Category Breakdown** â€” Performance by product category
- **Segment Analysis** â€” Customer segment comparison
- **Top Products** â€” Best selling products table
- **Top Customers** â€” Highest value customers
- **Treemap** â€” Sub-category performance with profit margins

---

## ğŸ”§ ETL Pipeline Features

- **Schema Validation** â€” Pandera enforces data types and constraints
- **Quality Checks** â€” Nulls, duplicates, range violations, business rules
- **Reconciliation** â€” Source-to-database verification
- **Logging** â€” Clear console output with status indicators
- **Idempotent** â€” Safe to re-run without duplicating data

---

## ğŸ“ License

This project is for educational and portfolio purposes.

---

## ğŸ‘¤ Author

**Aaditya Krishna**  
Graduate Student, Data Analytics Engineering  
Northeastern University

- GitHub: [@kizamehoshigaki](https://github.com/kizamehoshigaki)
- LinkedIn: [Aaditya Krishna](https://www.linkedin.com/in/aaditya-krishna/)

---
